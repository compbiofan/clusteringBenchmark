# Create folders for results of each datasets
for i in ./input/*.tsv; do 
	fileName=$(echo $i| cut -d'/' -f 3)
        #echo $fileName
        subfname=$(echo $fileName| cut -d'.' -f 1)
        #echo $subfname
        mkdir output/$subfname;
done

# This command will create all the files to run scclone in parallel
for i in ./input/*.tsv; do
	fileName=$(echo $i| cut -d'/' -f 3)
        #echo $fileName
        subfname=$(echo $fileName| cut -d'.' -f 1)
	echo "time python ../../BnpC/run_BnpC.py $i -pp 0.75 0.75 -o ./output/$subfname" >> run_bnpc.sh;
	echo "#" >> run_bnpc.sh;
done

conda activate pythonenv

# Run the python command to generate the slurm files
python gen_jobs.py -input run_bnpc.sh -n 2 -mem_per_cpu 4GB -p fan_q -algo bnpc

#Launch jobs
for i in `seq 0 6`; do sbatch run_bnpc.$i.slurm; done

# Get the consensus matrix
for dir in ./output/*/; do
        #echo $dir
        fileName=$(echo $dir| cut -d'/' -f 3)
        #echo $fileName
        gt_subfn1=$(echo $fileName| cut -d'_' -f 1)
        gt_subfn2=$(echo $fileName| cut -d'_' -f 2)
        gt_subfn3=$(echo $fileName| cut -d'_' -f 4)
	sc_in="${gt_subfn1}_${gt_subfn2}_D_${gt_subfn3}.tsv"
        gt="${gt_subfn1}_${gt_subfn2}_GT_${gt_subfn3}.tsv"
	#echo $sc_in
	python bnpc_getGmatrix.py -cc $dir/assignment.txt -gp $dir/genotypes_posterior_mean.tsv -input ../scclone/input/$sc_in -op consensus_genotype/$fileName.tsv
	python ../evaluateMetrics.py -cg ./consensus_genotype/$fileName.tsv -gtG ./ground_truth/$gt >> ./output/$fileName/eval_metrics.txt
done

