# Create folders for results of each datasets
for i in ./input/*.tsv; do 
	fileName=$(echo $i| cut -d'/' -f 3)
        #echo $fileName
        subfname=$(echo $fileName| cut -d'.' -f 1)
        #echo $subfname
        mkdir output/$subfname;
done

# This command will create all the files to run scclone in parallel
for i in ./input/*.tsv; do
	fileName=$(echo $i| cut -d'/' -f 3)
        #echo $fileName
        subfname=$(echo $fileName| cut -d'.' -f 1)
	echo "time python ../../BnpC/run_BnpC.py $i -pp 0.75 0.75 -o ./output/$subfname" >> run_bnpc.sh;
	echo "#" >> run_bnpc.sh;
done

conda activate pythonenv

# Run the python command to generate the slurm files
python gen_jobs.py -input run_bnpc.sh -n 2 -mem_per_cpu 4GB -p fan_q

#Launch jobs
for i in `seq 0 6`; do sbatch run_bnpc.$i.slurm; done

# Get the consensus matrix
python bnpc_getGmatrix.py -cc ./output/exp2_2_D_10_bnpc/assignment.txt -gp ./output/exp2_2_D_10_bnpc/genotypes_posterior_mean.tsv -input ../scclone/input/exp2_2_D_10.tsv -op consensus_genotype/exp2_2_D_10_CG.tsv

# Get the evaluation matrix
python evaluateMetrics.py -cg ./consensus_genotype/exp2_2_D_10_CG.tsv -gtG ./ground_truth/exp2_2_GT_10.tsv

