# Create folders for results of each datasets
for i in ./input/*.tsv; do 
	fileName=$(echo $i| cut -d'/' -f 3)
        #echo $fileName
        subfname=$(echo $fileName| cut -d'.' -f 1)
        #echo $subfname
        mkdir output/$subfname;
done

# This command will create all the files to run scclone in parallel
for i in ./input/*.tsv; do
	fileName=$(echo $i| cut -d'/' -f 3)
        #echo $fileName
        subfname=$(echo $fileName| cut -d'.' -f 1)
	echo "time ../../scclone-1.0/bin/scclone -i $i -a 0.01 -b 0.1 -o ./output/$subfname/$subfname" >> run_scclone.sh;
	echo "#" >> run_scclone.sh;
done

# Run the python command to generate the slurm files
python ../gen_jobs.py -input run_scclone.sh -n 2 -mem_per_cpu 4GB -p fan_q -algo scclone -sim false

#Launch jobs
for i in `seq 0 6`; do sbatch run_scclone.$i.slurm; done

conda activate pythonenv

# Run the python script to get the consensus matrix and evaluate
for dir in ./output/*/; do
        #echo $dir
        fileName=$(echo $dir| cut -d'/' -f 3)
        #echo $fileName
        gt_subfn1=$(echo $fileName| cut -d'_' -f 1)
        gt_subfn2=$(echo $fileName| cut -d'_' -f 2)
        gt_subfn3=$(echo $fileName| cut -d'_' -f 4)
        gt="${gt_subfn1}_${gt_subfn2}_GT_${gt_subfn3}.tsv"
	python scclone_getGmatrix.py -ca $dir/exp2_2_D_10.cell_assignment -cg $dir/exp2_2_D_10.clone_genotypes -op ./consensus_genotype/$fileName.tsv -input ./input/$fileName.tsv
	python ../evaluateMetrics.py -cg ./consensus_genotype/$fileName.tsv -gtG ./ground_truth/$gt > ./output/$fileName/eval_metrics.txt
done
